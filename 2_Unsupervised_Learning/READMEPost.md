# Unsupervised Learning: Titanic Passenger Clustering  

## ğŸ“Œ Project Overview  
This project applies unsupervised learning techniques to analyze the Titanic dataset, revealing hidden patterns among passengers without predefined survival labels.  

Using K-Means clustering, the goal was to:  
âœ” Identify distinct passenger groups based on ticket class, age, and fare.  
âœ” Apply Principal Component Analysis (PCA) for dimensionality reduction and visualization.  
âœ” Evaluate clustering effectiveness using silhouette scores and performance metrics.  

This project demonstrates how unsupervised learning enables data exploration and structure discovery, providing deeper insights into passenger segmentation and travel behaviors.

---

## ğŸ“Œ How I Achieved It  

### 1ï¸âƒ£ Data Preprocessing  
Before clustering, the dataset was cleaned, transformed, and standardized to improve model accuracy.  

âœ” Handled Missing Values:  
   - Imputed `Age` and `Fare` with the median to ensure completeness.  
   - Filled `Embarked` with the most common port.  

âœ” Categorical Encoding:  
   - Converted `Sex` to numerical values (`0 = male`, `1 = female`).  
   - Applied one-hot encoding to `Embarked`.  

âœ” Feature Selection:  
   - Retained Pclass, Age, Fare, SibSp, and Parch as key clustering features.  
   - Dropped irrelevant columns (`Name`, `Ticket`, `Cabin`) to simplify modeling.  

âœ” Feature Scaling:  
   - Used StandardScaler to normalize numerical features, ensuring that clustering was not biased by scale differences.  

This preprocessing pipeline provided a structured and uniform dataset, enabling more reliable clustering.

---

### 2ï¸âƒ£ Determining the Optimal Number of Clusters (`K`)  
Finding the right number of clusters (`K`) was critical for meaningful segmentation.  

âœ” The Elbow Method â†’ Plotted the Within-Cluster Sum of Squares (WCSS) to identify diminishing returns.  
âœ” Silhouette Scores â†’ Measured cluster cohesion and separation to validate `K`.  
âœ” Final Choice: `K=5` provided the best balance between interpretability and cluster quality.  

---

### 3ï¸âƒ£ K-Means Clustering Implementation  
After selecting the optimal `K`, K-Means clustering was applied to segment passengers based on their similarities.  

âœ” Assigned each passenger to one of five clusters, forming distinct groups:  
   - Cluster 0 â†’ Families traveling in lower ticket classes.  
   - Cluster 1 â†’ Wealthy passengers with high fares, mainly first-class.  
   - Cluster 2 â†’ Younger passengers with lower fares.  
   - Cluster 3 â†’ Single travelers or small family groups.  
   - Cluster 4 â†’ Older passengers traveling in second-class.  

âœ” Saved clustered passenger data into `titanic_clusters.csv` for further exploration.  

---

### 4ï¸âƒ£ Visualization & Interpretation  
To analyze clustering effectiveness, multiple visualizations were generated:  

âœ” PCA Scatter Plot â†’ Reduced dimensionality and plotted clusters to reveal clear group separations.  
âœ” Feature Correlation Heatmap â†’ Showed relationships between clustering attributes.  
âœ” Boxplots â†’ Explored age and fare distributions across clusters.  

Each visualization helped validate clustering performance, ensuring that clusters represented real-world groupings within the dataset.

---

## ğŸ“Š Key Findings & Takeaways  

âœ” Unsupervised Learning Unveils Hidden Structures â†’ Clustering grouped passengers with similar characteristics, showcasing the power of machine learning beyond predictive tasks.  
âœ” The Elbow Method & Silhouette Scores Matter â†’ Selecting the right `K` is crucial to forming meaningful and distinct clusters.  
âœ” Scaling Data is Essential â†’ Standardizing numerical features prevented clustering bias, leading to better group separation.  
âœ” Interpretability through Visuals â†’ Using PCA, heatmaps, and boxplots enhanced cluster explainability.  

---

## ğŸ“Œ Next Steps & Future Enhancements  

âœ” Test Alternative Clustering Algorithms â†’ Implement DBSCAN or Hierarchical Clustering for a comparative analysis.  
âœ” Hyperparameter Tuning â†’ Adjust clustering parameters for improved separation.  
âœ” Feature Engineering Expansion â†’ Combine `SibSp` and `Parch` into a unified "Family Size" feature for deeper insights.  

Beyond Titanic passenger clustering, these techniques can be applied to:  
âœ” Customer Segmentation â†’ Grouping users based on behavior for targeted marketing.  
âœ” Anomaly Detection â†’ Identifying fraudulent transactions or unusual data points.  
âœ” Medical Data Analysis â†’ Clustering patient profiles for disease classification.  

---

## ğŸ“Œ Final Thoughts  
This project highlights the power of unsupervised learning in exploratory data analysis.  

By structuring the dataset, selecting optimal clusters, and applying visual techniques, this approach provides actionable insights without relying on predefined labels. These data-driven clustering methods can be adapted for numerous real-world applications, making them invaluable for exploratory machine learning.  

---

## ğŸ“© Questions & Contributions  
ğŸ‘¤ Anthony Broderick  
ğŸ“© For collaboration, feedback, or suggestions, feel free to reach out.  
